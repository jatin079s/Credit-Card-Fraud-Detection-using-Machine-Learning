{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Credit Card Fraud Detection</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see all the columns\n",
    "pd.options.display.max_columns = None\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking dimensions \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 284807 rows and 31 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Checking dataframe info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any null values.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data to StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Amount'] = ss.fit_transform(pd.DataFrame(df['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "     Amount  Class  \n",
       "0  0.244964      0  \n",
       "1 -0.342475      0  \n",
       "2  1.160686      0  \n",
       "3  0.140534      0  \n",
       "4 -0.073403      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the \"Time\" column.\n",
    "df.drop(['Time'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9144"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for duplicate values in dataframe.\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 9144 duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping duplicate rows\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1       473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the dataset is balanced dataset or imbalanced dataset!\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data is highly imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the countplot on class feature.\n",
    "ax = sns.countplot(x='Class', data=df)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + p.get_width() / 2, p.get_height()), \n",
    "                ha='center', va='bottom', fontsize=12, color='black')\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of Class Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the efficiency of machine learning model with imbalanced data.\n",
    "x = df.drop('Class',axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into training data and testing data.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing some machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================Logistic Regression==============\n",
      "Accuracy : 0.9992200678359603\n",
      "Precision : 0.8870967741935484\n",
      "Recall : 0.6043956043956044\n",
      "F1 Score : 0.718954248366013\n",
      "\n",
      "=================Decision Tree Classifier==============\n",
      "Accuracy : 0.9989479984764116\n",
      "Precision : 0.6701030927835051\n",
      "Recall : 0.7142857142857143\n",
      "F1 Score : 0.6914893617021276\n",
      "\n",
      "=================Random Forest Classifier==============\n",
      "Accuracy : 0.999419585366296\n",
      "Precision : 0.9041095890410958\n",
      "Recall : 0.7252747252747253\n",
      "F1 Score : 0.8048780487804877\n"
     ]
    }
   ],
   "source": [
    "classifier = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f'\\n================={name}==============')\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precison = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1_score = f1_score(y_test, y_pred)\n",
    "    print(f'Accuracy : {accuracy}')\n",
    "    print(f'Precision : {precison}')\n",
    "    print(f'Recall : {recall}')\n",
    "    print(f'F1 Score : {F1_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the dataset using undersampling and oversampling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Undersampling technique\n",
    "normal = df[df['Class']==0]\n",
    "fraud = df[df['Class']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275190, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sample = normal.sample(n=473)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(473, 30)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_undersample_df = pd.concat([normal_sample,fraud],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.253764</td>\n",
       "      <td>0.360733</td>\n",
       "      <td>0.651938</td>\n",
       "      <td>0.825910</td>\n",
       "      <td>-0.391299</td>\n",
       "      <td>-0.936982</td>\n",
       "      <td>-0.010430</td>\n",
       "      <td>-0.298631</td>\n",
       "      <td>1.299349</td>\n",
       "      <td>-0.444579</td>\n",
       "      <td>0.762179</td>\n",
       "      <td>-2.032285</td>\n",
       "      <td>2.156836</td>\n",
       "      <td>1.635022</td>\n",
       "      <td>0.273375</td>\n",
       "      <td>0.266060</td>\n",
       "      <td>0.296485</td>\n",
       "      <td>-0.291091</td>\n",
       "      <td>-0.323564</td>\n",
       "      <td>-0.113001</td>\n",
       "      <td>-0.402775</td>\n",
       "      <td>-0.917767</td>\n",
       "      <td>0.140746</td>\n",
       "      <td>0.319456</td>\n",
       "      <td>0.199773</td>\n",
       "      <td>0.055038</td>\n",
       "      <td>-0.055466</td>\n",
       "      <td>0.013896</td>\n",
       "      <td>-0.325323</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.691361</td>\n",
       "      <td>0.284309</td>\n",
       "      <td>1.588772</td>\n",
       "      <td>-0.030662</td>\n",
       "      <td>0.707697</td>\n",
       "      <td>0.545994</td>\n",
       "      <td>0.820804</td>\n",
       "      <td>-0.002959</td>\n",
       "      <td>0.068054</td>\n",
       "      <td>-0.690185</td>\n",
       "      <td>0.510952</td>\n",
       "      <td>1.021487</td>\n",
       "      <td>-0.172385</td>\n",
       "      <td>-0.344483</td>\n",
       "      <td>-1.727039</td>\n",
       "      <td>-1.425276</td>\n",
       "      <td>0.401676</td>\n",
       "      <td>-0.296292</td>\n",
       "      <td>2.086117</td>\n",
       "      <td>0.300595</td>\n",
       "      <td>-0.298101</td>\n",
       "      <td>-0.539681</td>\n",
       "      <td>-0.229958</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>0.600228</td>\n",
       "      <td>-0.119365</td>\n",
       "      <td>-0.127321</td>\n",
       "      <td>-0.159204</td>\n",
       "      <td>-0.147568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.214789</td>\n",
       "      <td>0.964558</td>\n",
       "      <td>0.425983</td>\n",
       "      <td>2.754122</td>\n",
       "      <td>0.219037</td>\n",
       "      <td>-0.962153</td>\n",
       "      <td>0.554382</td>\n",
       "      <td>-0.448684</td>\n",
       "      <td>0.038055</td>\n",
       "      <td>0.334320</td>\n",
       "      <td>0.898959</td>\n",
       "      <td>-1.922072</td>\n",
       "      <td>2.667476</td>\n",
       "      <td>1.750035</td>\n",
       "      <td>-0.679323</td>\n",
       "      <td>0.151009</td>\n",
       "      <td>0.310414</td>\n",
       "      <td>-0.473391</td>\n",
       "      <td>-1.220411</td>\n",
       "      <td>-0.153084</td>\n",
       "      <td>-0.132592</td>\n",
       "      <td>-0.095128</td>\n",
       "      <td>-0.063847</td>\n",
       "      <td>0.679995</td>\n",
       "      <td>0.701946</td>\n",
       "      <td>0.006434</td>\n",
       "      <td>-0.058182</td>\n",
       "      <td>0.008913</td>\n",
       "      <td>-0.350791</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.119443</td>\n",
       "      <td>3.069328</td>\n",
       "      <td>-3.837926</td>\n",
       "      <td>1.352897</td>\n",
       "      <td>-2.981258</td>\n",
       "      <td>-1.140479</td>\n",
       "      <td>-1.615365</td>\n",
       "      <td>3.205357</td>\n",
       "      <td>0.705660</td>\n",
       "      <td>0.291632</td>\n",
       "      <td>0.924179</td>\n",
       "      <td>-1.146701</td>\n",
       "      <td>0.890503</td>\n",
       "      <td>4.444064</td>\n",
       "      <td>-0.713340</td>\n",
       "      <td>0.670114</td>\n",
       "      <td>1.666943</td>\n",
       "      <td>0.978519</td>\n",
       "      <td>0.188116</td>\n",
       "      <td>-0.105337</td>\n",
       "      <td>0.087085</td>\n",
       "      <td>0.027616</td>\n",
       "      <td>-0.155219</td>\n",
       "      <td>0.285081</td>\n",
       "      <td>-0.402891</td>\n",
       "      <td>-0.450848</td>\n",
       "      <td>0.233639</td>\n",
       "      <td>-0.031828</td>\n",
       "      <td>0.006558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.208225</td>\n",
       "      <td>-0.167378</td>\n",
       "      <td>0.669688</td>\n",
       "      <td>0.655443</td>\n",
       "      <td>-0.972892</td>\n",
       "      <td>-0.891836</td>\n",
       "      <td>-0.229481</td>\n",
       "      <td>-0.067089</td>\n",
       "      <td>0.886016</td>\n",
       "      <td>-0.268192</td>\n",
       "      <td>-0.670582</td>\n",
       "      <td>-0.074929</td>\n",
       "      <td>-1.384231</td>\n",
       "      <td>0.069249</td>\n",
       "      <td>-0.224337</td>\n",
       "      <td>-0.428055</td>\n",
       "      <td>0.326595</td>\n",
       "      <td>-0.564340</td>\n",
       "      <td>0.204325</td>\n",
       "      <td>-0.192163</td>\n",
       "      <td>-0.087997</td>\n",
       "      <td>-0.075031</td>\n",
       "      <td>-0.027771</td>\n",
       "      <td>0.766590</td>\n",
       "      <td>0.450916</td>\n",
       "      <td>0.654504</td>\n",
       "      <td>-0.042104</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>-0.309250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  1.253764  0.360733  0.651938  0.825910 -0.391299 -0.936982 -0.010430   \n",
       "1 -0.691361  0.284309  1.588772 -0.030662  0.707697  0.545994  0.820804   \n",
       "2  1.214789  0.964558  0.425983  2.754122  0.219037 -0.962153  0.554382   \n",
       "3 -5.119443  3.069328 -3.837926  1.352897 -2.981258 -1.140479 -1.615365   \n",
       "4  1.208225 -0.167378  0.669688  0.655443 -0.972892 -0.891836 -0.229481   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0 -0.298631  1.299349 -0.444579  0.762179 -2.032285  2.156836  1.635022   \n",
       "1 -0.002959  0.068054 -0.690185  0.510952  1.021487 -0.172385 -0.344483   \n",
       "2 -0.448684  0.038055  0.334320  0.898959 -1.922072  2.667476  1.750035   \n",
       "3  3.205357  0.705660  0.291632  0.924179 -1.146701  0.890503  4.444064   \n",
       "4 -0.067089  0.886016 -0.268192 -0.670582 -0.074929 -1.384231  0.069249   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  0.273375  0.266060  0.296485 -0.291091 -0.323564 -0.113001 -0.402775   \n",
       "1 -1.727039 -1.425276  0.401676 -0.296292  2.086117  0.300595 -0.298101   \n",
       "2 -0.679323  0.151009  0.310414 -0.473391 -1.220411 -0.153084 -0.132592   \n",
       "3 -0.713340  0.670114  1.666943  0.978519  0.188116 -0.105337  0.087085   \n",
       "4 -0.224337 -0.428055  0.326595 -0.564340  0.204325 -0.192163 -0.087997   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0 -0.917767  0.140746  0.319456  0.199773  0.055038 -0.055466  0.013896   \n",
       "1 -0.539681 -0.229958  0.727200  0.600228 -0.119365 -0.127321 -0.159204   \n",
       "2 -0.095128 -0.063847  0.679995  0.701946  0.006434 -0.058182  0.008913   \n",
       "3  0.027616 -0.155219  0.285081 -0.402891 -0.450848  0.233639 -0.031828   \n",
       "4 -0.075031 -0.027771  0.766590  0.450916  0.654504 -0.042104  0.008302   \n",
       "\n",
       "     Amount  Class  \n",
       "0 -0.325323      0  \n",
       "1 -0.147568      0  \n",
       "2 -0.350791      0  \n",
       "3  0.006558      0  \n",
       "4 -0.309250      0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_undersample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    473\n",
       "1    473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_undersample_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = new_undersample_df.drop('Class',axis=1)\n",
    "y = new_undersample_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================Logistic Regression==============\n",
      "Accuracy : 0.9263157894736842\n",
      "Precision : 0.9489795918367347\n",
      "Recall : 0.9117647058823529\n",
      "F1 Score : 0.9300000000000002\n",
      "\n",
      "=================Decision Tree Classifier==============\n",
      "Accuracy : 0.8789473684210526\n",
      "Precision : 0.8910891089108911\n",
      "Recall : 0.8823529411764706\n",
      "F1 Score : 0.8866995073891626\n",
      "\n",
      "=================Random Forest Classifier==============\n",
      "Accuracy : 0.9421052631578948\n",
      "Precision : 0.9789473684210527\n",
      "Recall : 0.9117647058823529\n",
      "F1 Score : 0.9441624365482234\n"
     ]
    }
   ],
   "source": [
    "classifier = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f'\\n================={name}==============')\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precison = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1_score = f1_score(y_test, y_pred)\n",
    "    print(f'Accuracy : {accuracy}')\n",
    "    print(f'Precision : {precison}')\n",
    "    print(f'Recall : {recall}')\n",
    "    print(f'F1 Score : {F1_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem in undersampling technique i.e. data lost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Oversampling technique (Using SMOTE)\n",
    "x = df.drop('Class',axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_res, y_res = SMOTE().fit_resample(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    275190\n",
       "1    275190\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_res,y_res,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================Logistic Regression==============\n",
      "Accuracy : 0.9447472655256368\n",
      "Precision : 0.973169552181062\n",
      "Recall : 0.9146410195807502\n",
      "F1 Score : 0.942997994339163\n",
      "\n",
      "=================Decision Tree Classifier==============\n",
      "Accuracy : 0.9983102583669464\n",
      "Precision : 0.9976035293476879\n",
      "Recall : 0.9990182353689798\n",
      "F1 Score : 0.9983103811634751\n",
      "\n",
      "=================Random Forest Classifier==============\n",
      "Accuracy : 0.9999273229405138\n",
      "Precision : 0.9998545745396376\n",
      "Recall : 1.0\n",
      "F1 Score : 0.9999272819822931\n"
     ]
    }
   ],
   "source": [
    "classifier = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "for name, clf in classifier.items():\n",
    "    print(f'\\n================={name}==============')\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precison = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1_score = f1_score(y_test, y_pred)\n",
    "    print(f'Accuracy : {accuracy}')\n",
    "    print(f'Precision : {precison}')\n",
    "    print(f'Recall : {recall}')\n",
    "    print(f'F1 Score : {F1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['credit_card_model.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(dtc, \"credit_card_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"credit_card_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model.predict([[-1.3598071336738,-0.0727811733098497,2.53634673796914,1.37815522427443,-0.338320769942518,0.462387777762292,0.239598554061257,0.0986979012610507,0.363786969611213,0.0907941719789316,-0.551599533260813,-0.617800855762348,-0.991389847235408,-0.311169353699879,1.46817697209427,-0.470400525259478,0.207971241929242,0.0257905801985591,0.403992960255733,0.251412098239705,-0.018306777944153,0.277837575558899,-0.110473910188767,0.0669280749146731,0.128539358273528,-0.189114843888824,0.133558376740387,-0.0210530534538215,149.62]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Transaction\n"
     ]
    }
   ],
   "source": [
    "if pred1[0] == 0:\n",
    "    print('Normal Transaction')\n",
    "else:\n",
    "    print('Fraud Transaction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = model.predict([[-2.3122265423263,1.95199201064158,-1.60985073229769,3.9979055875468,-0.522187864667764,-1.42654531920595,-2.53738730624579,1.39165724829804,-2.77008927719433,-2.77227214465915,3.20203320709635,-2.89990738849473,-0.595221881324605,-4.28925378244217,0.389724120274487,-1.14074717980657,-2.83005567450437,-0.0168224681808257,0.416955705037907,0.126910559061474,0.517232370861764,-0.0350493686052974,-0.465211076182388,0.320198198514526,0.0445191674731724,0.177839798284401,0.261145002567677,-0.143275874698919,-0.35322939296682354]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Transaction\n"
     ]
    }
   ],
   "source": [
    "if pred2[0] == 0:\n",
    "    print('Normal Transaction')\n",
    "else:\n",
    "    print('Fraud Transaction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
